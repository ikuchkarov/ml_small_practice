{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "Firstly, make imports, read data, pick out target column and find missings in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Name           1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "Age            1046 non-null float64\n",
      "SibSp          1309 non-null int64\n",
      "Parch          1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 122.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "y_train = np.array(train['Survived'])\n",
    "del train['Survived']\n",
    "\n",
    "X_all = pd.concat([train, test])\n",
    "print(X_all.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all machine learning algorithms work with numerical vectors. Convert data to appropriate format, filling in blanks and encode categorial features. Missing may be useful information, save it in additional column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all['age_null'] = pd.isnull(X_all['Age'])\n",
    "X_all['cabin_null'] = pd.isnull(X_all['Cabin'])\n",
    "\n",
    "X_all['isMale'] = X_all['Sex'] == 'male'\n",
    "\n",
    "X_all.fillna(value = {'Age': X_all['Age'].mean(),\n",
    "                      'Fare' : X_all['Fare'].mean(),\n",
    "                      'Embarked' : X_all['Embarked'].mode()[0]},\n",
    "             inplace = True)\n",
    "\n",
    "X_all['Embarked_S'] = X_all['Embarked'] == 'S'\n",
    "X_all['Embarked_C'] = X_all['Embarked'] == 'C'\n",
    "X_all['Embarked_Q'] = X_all['Embarked'] == 'Q'\n",
    "\n",
    "del X_all['Cabin'], X_all['PassengerId'], X_all['Name'], X_all['Ticket'], X_all['Embarked'], X_all['Sex']\n",
    "\n",
    "X_train = np.array(X_all.iloc[train.index], dtype=np.dtype('float64'))\n",
    "X_test = np.array(X_all.iloc[X_train.shape[0]:], dtype=np.dtype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale all features with StandardScaler thus mean will be zero and standard deviation will be one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try linear model - logistic regression. Pick up regulazation parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.031 \n",
      "Accuracy: 0.788 (+/- 0.103)\n",
      "\n",
      "C = 0.062 \n",
      "Accuracy: 0.792 (+/- 0.092)\n",
      "\n",
      "C = 0.125 \n",
      "Accuracy: 0.795 (+/- 0.090)\n",
      "\n",
      "C = 0.250 \n",
      "Accuracy: 0.796 (+/- 0.087)\n",
      "\n",
      "C = 0.500 \n",
      "Accuracy: 0.798 (+/- 0.093)\n",
      "\n",
      "C = 1.000 \n",
      "Accuracy: 0.798 (+/- 0.093)\n",
      "\n",
      "C = 2.000 \n",
      "Accuracy: 0.798 (+/- 0.093)\n",
      "\n",
      "C = 4.000 \n",
      "Accuracy: 0.798 (+/- 0.093)\n",
      "\n",
      "C = 8.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n",
      "C = 16.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n",
      "C = 32.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n",
      "C = 64.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n",
      "C = 128.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n",
      "C = 256.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n",
      "C = 512.000 \n",
      "Accuracy: 0.799 (+/- 0.091)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=44)\n",
    "\n",
    "for C in [2.0 ** i for i in range(-5, 10)]:\n",
    "    clf = LogisticRegression(C = C)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=kfold)\n",
    "    print(\"C = %0.3f \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (C, scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our baseline is ** 0.799 (+/- 0.091) **\n",
    "\n",
    "Now try SVM with RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.031 \n",
      "Accuracy: 0.739 (+/- 0.073)\n",
      "\n",
      "C = 0.062 \n",
      "Accuracy: 0.788 (+/- 0.092)\n",
      "\n",
      "C = 0.125 \n",
      "Accuracy: 0.805 (+/- 0.100)\n",
      "\n",
      "C = 0.250 \n",
      "Accuracy: 0.810 (+/- 0.092)\n",
      "\n",
      "C = 0.500 \n",
      "Accuracy: 0.825 (+/- 0.077)\n",
      "\n",
      "C = 1.000 \n",
      "Accuracy: 0.820 (+/- 0.063)\n",
      "\n",
      "C = 2.000 \n",
      "Accuracy: 0.826 (+/- 0.091)\n",
      "\n",
      "C = 4.000 \n",
      "Accuracy: 0.834 (+/- 0.075)\n",
      "\n",
      "C = 8.000 \n",
      "Accuracy: 0.824 (+/- 0.081)\n",
      "\n",
      "C = 16.000 \n",
      "Accuracy: 0.814 (+/- 0.075)\n",
      "\n",
      "C = 32.000 \n",
      "Accuracy: 0.803 (+/- 0.071)\n",
      "\n",
      "C = 64.000 \n",
      "Accuracy: 0.786 (+/- 0.054)\n",
      "\n",
      "C = 128.000 \n",
      "Accuracy: 0.781 (+/- 0.067)\n",
      "\n",
      "C = 256.000 \n",
      "Accuracy: 0.779 (+/- 0.081)\n",
      "\n",
      "C = 512.000 \n",
      "Accuracy: 0.783 (+/- 0.074)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=44)\n",
    "\n",
    "for C in [2.0 ** i for i in range(-5, 10)]:\n",
    "    clf = SVC(C = C, kernel='rbf')\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=kfold)\n",
    "    print(\"C = %0.3f \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (C, scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results improve to ** 0.834 (+/- 0.075) **\n",
    "\n",
    "Maybe it means that data have a cluster structure. \n",
    "Try K-nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 1 \n",
      "Accuracy: 0.746 (+/- 0.102)\n",
      "\n",
      "n_neighbors = 2 \n",
      "Accuracy: 0.781 (+/- 0.096)\n",
      "\n",
      "n_neighbors = 3 \n",
      "Accuracy: 0.787 (+/- 0.080)\n",
      "\n",
      "n_neighbors = 4 \n",
      "Accuracy: 0.783 (+/- 0.083)\n",
      "\n",
      "n_neighbors = 5 \n",
      "Accuracy: 0.794 (+/- 0.069)\n",
      "\n",
      "n_neighbors = 6 \n",
      "Accuracy: 0.800 (+/- 0.071)\n",
      "\n",
      "n_neighbors = 7 \n",
      "Accuracy: 0.813 (+/- 0.072)\n",
      "\n",
      "n_neighbors = 8 \n",
      "Accuracy: 0.805 (+/- 0.085)\n",
      "\n",
      "n_neighbors = 9 \n",
      "Accuracy: 0.811 (+/- 0.069)\n",
      "\n",
      "n_neighbors = 10 \n",
      "Accuracy: 0.809 (+/- 0.088)\n",
      "\n",
      "n_neighbors = 11 \n",
      "Accuracy: 0.807 (+/- 0.071)\n",
      "\n",
      "n_neighbors = 12 \n",
      "Accuracy: 0.814 (+/- 0.074)\n",
      "\n",
      "n_neighbors = 13 \n",
      "Accuracy: 0.806 (+/- 0.078)\n",
      "\n",
      "n_neighbors = 14 \n",
      "Accuracy: 0.808 (+/- 0.084)\n",
      "\n",
      "n_neighbors = 15 \n",
      "Accuracy: 0.815 (+/- 0.079)\n",
      "\n",
      "n_neighbors = 16 \n",
      "Accuracy: 0.806 (+/- 0.084)\n",
      "\n",
      "n_neighbors = 17 \n",
      "Accuracy: 0.807 (+/- 0.089)\n",
      "\n",
      "n_neighbors = 18 \n",
      "Accuracy: 0.803 (+/- 0.083)\n",
      "\n",
      "n_neighbors = 19 \n",
      "Accuracy: 0.810 (+/- 0.063)\n",
      "\n",
      "n_neighbors = 20 \n",
      "Accuracy: 0.814 (+/- 0.070)\n",
      "\n",
      "n_neighbors = 21 \n",
      "Accuracy: 0.801 (+/- 0.078)\n",
      "\n",
      "n_neighbors = 22 \n",
      "Accuracy: 0.803 (+/- 0.067)\n",
      "\n",
      "n_neighbors = 23 \n",
      "Accuracy: 0.800 (+/- 0.073)\n",
      "\n",
      "n_neighbors = 24 \n",
      "Accuracy: 0.808 (+/- 0.077)\n",
      "\n",
      "n_neighbors = 25 \n",
      "Accuracy: 0.807 (+/- 0.067)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=44)\n",
    "\n",
    "for n_neighbors in range(1, 26):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=kfold)\n",
    "    print(\"n_neighbors = %d \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (n_neighbors, scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than logistic regression: ** 0.815 (+/- 0.079) **.\n",
    "Then try add information about cluster structure to features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 2 \n",
      "C = 0.250 \n",
      "Accuracy: 0.795 (+/- 0.103)\n",
      "\n",
      "n_clusters = 3 \n",
      "C = 0.250 \n",
      "Accuracy: 0.796 (+/- 0.105)\n",
      "\n",
      "n_clusters = 4 \n",
      "C = 64.000 \n",
      "Accuracy: 0.803 (+/- 0.102)\n",
      "\n",
      "n_clusters = 5 \n",
      "C = 64.000 \n",
      "Accuracy: 0.807 (+/- 0.103)\n",
      "\n",
      "n_clusters = 6 \n",
      "C = 8.000 \n",
      "Accuracy: 0.804 (+/- 0.109)\n",
      "\n",
      "n_clusters = 7 \n",
      "C = 32.000 \n",
      "Accuracy: 0.806 (+/- 0.099)\n",
      "\n",
      "n_clusters = 8 \n",
      "C = 128.000 \n",
      "Accuracy: 0.807 (+/- 0.105)\n",
      "\n",
      "n_clusters = 9 \n",
      "C = 2.000 \n",
      "Accuracy: 0.805 (+/- 0.103)\n",
      "\n",
      "n_clusters = 10 \n",
      "C = 4.000 \n",
      "Accuracy: 0.806 (+/- 0.098)\n",
      "\n",
      "n_clusters = 11 \n",
      "C = 8.000 \n",
      "Accuracy: 0.813 (+/- 0.104)\n",
      "\n",
      "n_clusters = 12 \n",
      "C = 32.000 \n",
      "Accuracy: 0.807 (+/- 0.110)\n",
      "\n",
      "n_clusters = 13 \n",
      "C = 16.000 \n",
      "Accuracy: 0.804 (+/- 0.105)\n",
      "\n",
      "n_clusters = 14 \n",
      "C = 16.000 \n",
      "Accuracy: 0.820 (+/- 0.086)\n",
      "\n",
      "n_clusters = 15 \n",
      "C = 16.000 \n",
      "Accuracy: 0.815 (+/- 0.096)\n",
      "\n",
      "n_clusters = 16 \n",
      "C = 128.000 \n",
      "Accuracy: 0.824 (+/- 0.093)\n",
      "\n",
      "n_clusters = 17 \n",
      "C = 8.000 \n",
      "Accuracy: 0.822 (+/- 0.101)\n",
      "\n",
      "n_clusters = 18 \n",
      "C = 16.000 \n",
      "Accuracy: 0.818 (+/- 0.092)\n",
      "\n",
      "n_clusters = 19 \n",
      "C = 8.000 \n",
      "Accuracy: 0.823 (+/- 0.098)\n",
      "\n",
      "n_clusters = 20 \n",
      "C = 8.000 \n",
      "Accuracy: 0.813 (+/- 0.103)\n",
      "\n",
      "n_clusters = 21 \n",
      "C = 8.000 \n",
      "Accuracy: 0.822 (+/- 0.102)\n",
      "\n",
      "n_clusters = 22 \n",
      "C = 4.000 \n",
      "Accuracy: 0.827 (+/- 0.070)\n",
      "\n",
      "n_clusters = 23 \n",
      "C = 8.000 \n",
      "Accuracy: 0.829 (+/- 0.092)\n",
      "\n",
      "n_clusters = 24 \n",
      "C = 4.000 \n",
      "Accuracy: 0.826 (+/- 0.065)\n",
      "\n",
      "n_clusters = 25 \n",
      "C = 8.000 \n",
      "Accuracy: 0.822 (+/- 0.068)\n",
      "\n",
      "n_clusters = 26 \n",
      "C = 8.000 \n",
      "Accuracy: 0.824 (+/- 0.068)\n",
      "\n",
      "n_clusters = 27 \n",
      "C = 64.000 \n",
      "Accuracy: 0.826 (+/- 0.077)\n",
      "\n",
      "n_clusters = 28 \n",
      "C = 4.000 \n",
      "Accuracy: 0.828 (+/- 0.088)\n",
      "\n",
      "n_clusters = 29 \n",
      "C = 16.000 \n",
      "Accuracy: 0.824 (+/- 0.060)\n",
      "\n",
      "n_clusters = 30 \n",
      "C = 32.000 \n",
      "Accuracy: 0.827 (+/- 0.091)\n",
      "\n",
      "n_clusters = 31 \n",
      "C = 32.000 \n",
      "Accuracy: 0.822 (+/- 0.074)\n",
      "\n",
      "n_clusters = 32 \n",
      "C = 8.000 \n",
      "Accuracy: 0.832 (+/- 0.061)\n",
      "\n",
      "n_clusters = 33 \n",
      "C = 8.000 \n",
      "Accuracy: 0.829 (+/- 0.062)\n",
      "\n",
      "n_clusters = 34 \n",
      "C = 16.000 \n",
      "Accuracy: 0.820 (+/- 0.088)\n",
      "\n",
      "n_clusters = 35 \n",
      "C = 64.000 \n",
      "Accuracy: 0.831 (+/- 0.090)\n",
      "\n",
      "n_clusters = 36 \n",
      "C = 8.000 \n",
      "Accuracy: 0.823 (+/- 0.065)\n",
      "\n",
      "n_clusters = 37 \n",
      "C = 32.000 \n",
      "Accuracy: 0.827 (+/- 0.082)\n",
      "\n",
      "n_clusters = 38 \n",
      "C = 4.000 \n",
      "Accuracy: 0.828 (+/- 0.063)\n",
      "\n",
      "n_clusters = 39 \n",
      "C = 2.000 \n",
      "Accuracy: 0.818 (+/- 0.067)\n",
      "\n",
      "n_clusters = 40 \n",
      "C = 64.000 \n",
      "Accuracy: 0.827 (+/- 0.077)\n",
      "\n",
      "n_clusters = 41 \n",
      "C = 8.000 \n",
      "Accuracy: 0.825 (+/- 0.076)\n",
      "\n",
      "n_clusters = 42 \n",
      "C = 8.000 \n",
      "Accuracy: 0.824 (+/- 0.075)\n",
      "\n",
      "n_clusters = 43 \n",
      "C = 32.000 \n",
      "Accuracy: 0.827 (+/- 0.090)\n",
      "\n",
      "n_clusters = 44 \n",
      "C = 16.000 \n",
      "Accuracy: 0.826 (+/- 0.087)\n",
      "\n",
      "n_clusters = 45 \n",
      "C = 4.000 \n",
      "Accuracy: 0.824 (+/- 0.073)\n",
      "\n",
      "n_clusters = 46 \n",
      "C = 8.000 \n",
      "Accuracy: 0.828 (+/- 0.085)\n",
      "\n",
      "n_clusters = 47 \n",
      "C = 8.000 \n",
      "Accuracy: 0.826 (+/- 0.074)\n",
      "\n",
      "n_clusters = 48 \n",
      "C = 128.000 \n",
      "Accuracy: 0.822 (+/- 0.076)\n",
      "\n",
      "n_clusters = 49 \n",
      "C = 8.000 \n",
      "Accuracy: 0.825 (+/- 0.072)\n",
      "\n",
      "n_clusters = 50 \n",
      "C = 4.000 \n",
      "Accuracy: 0.826 (+/- 0.068)\n",
      "\n",
      "n_clusters = 51 \n",
      "C = 8.000 \n",
      "Accuracy: 0.822 (+/- 0.074)\n",
      "\n",
      "n_clusters = 52 \n",
      "C = 8.000 \n",
      "Accuracy: 0.825 (+/- 0.077)\n",
      "\n",
      "n_clusters = 53 \n",
      "C = 4.000 \n",
      "Accuracy: 0.822 (+/- 0.075)\n",
      "\n",
      "n_clusters = 54 \n",
      "C = 4.000 \n",
      "Accuracy: 0.822 (+/- 0.072)\n",
      "\n",
      "n_clusters = 55 \n",
      "C = 4.000 \n",
      "Accuracy: 0.820 (+/- 0.067)\n",
      "\n",
      "n_clusters = 56 \n",
      "C = 4.000 \n",
      "Accuracy: 0.820 (+/- 0.067)\n",
      "\n",
      "n_clusters = 57 \n",
      "C = 4.000 \n",
      "Accuracy: 0.822 (+/- 0.069)\n",
      "\n",
      "n_clusters = 58 \n",
      "C = 4.000 \n",
      "Accuracy: 0.820 (+/- 0.071)\n",
      "\n",
      "n_clusters = 59 \n",
      "C = 4.000 \n",
      "Accuracy: 0.820 (+/- 0.069)\n",
      "\n",
      "n_clusters = 60 \n",
      "C = 0.500 \n",
      "Accuracy: 0.816 (+/- 0.073)\n",
      "\n",
      "n_clusters = 61 \n",
      "C = 64.000 \n",
      "Accuracy: 0.817 (+/- 0.081)\n",
      "\n",
      "n_clusters = 62 \n",
      "C = 8.000 \n",
      "Accuracy: 0.829 (+/- 0.085)\n",
      "\n",
      "n_clusters = 63 \n",
      "C = 4.000 \n",
      "Accuracy: 0.816 (+/- 0.077)\n",
      "\n",
      "n_clusters = 64 \n",
      "C = 8.000 \n",
      "Accuracy: 0.817 (+/- 0.080)\n",
      "\n",
      "n_clusters = 65 \n",
      "C = 4.000 \n",
      "Accuracy: 0.826 (+/- 0.078)\n",
      "\n",
      "n_clusters = 66 \n",
      "C = 2.000 \n",
      "Accuracy: 0.820 (+/- 0.075)\n",
      "\n",
      "n_clusters = 67 \n",
      "C = 8.000 \n",
      "Accuracy: 0.820 (+/- 0.095)\n",
      "\n",
      "n_clusters = 68 \n",
      "C = 4.000 \n",
      "Accuracy: 0.818 (+/- 0.092)\n",
      "\n",
      "n_clusters = 69 \n",
      "C = 0.500 \n",
      "Accuracy: 0.818 (+/- 0.068)\n",
      "\n",
      "n_clusters = 70 \n",
      "C = 0.500 \n",
      "Accuracy: 0.817 (+/- 0.081)\n",
      "\n",
      "n_clusters = 71 \n",
      "C = 0.500 \n",
      "Accuracy: 0.819 (+/- 0.071)\n",
      "\n",
      "n_clusters = 72 \n",
      "C = 1.000 \n",
      "Accuracy: 0.818 (+/- 0.073)\n",
      "\n",
      "n_clusters = 73 \n",
      "C = 0.500 \n",
      "Accuracy: 0.818 (+/- 0.068)\n",
      "\n",
      "n_clusters = 74 \n",
      "C = 0.500 \n",
      "Accuracy: 0.818 (+/- 0.068)\n",
      "\n",
      "n_clusters = 75 \n",
      "C = 0.500 \n",
      "Accuracy: 0.818 (+/- 0.068)\n",
      "\n",
      "n_clusters = 76 \n",
      "C = 0.500 \n",
      "Accuracy: 0.819 (+/- 0.082)\n",
      "\n",
      "n_clusters = 77 \n",
      "C = 0.500 \n",
      "Accuracy: 0.818 (+/- 0.068)\n",
      "\n",
      "n_clusters = 78 \n",
      "C = 0.500 \n",
      "Accuracy: 0.816 (+/- 0.078)\n",
      "\n",
      "n_clusters = 79 \n",
      "C = 1.000 \n",
      "Accuracy: 0.822 (+/- 0.070)\n",
      "\n",
      "n_clusters = 80 \n",
      "C = 4.000 \n",
      "Accuracy: 0.817 (+/- 0.083)\n",
      "\n",
      "n_clusters = 81 \n",
      "C = 8.000 \n",
      "Accuracy: 0.822 (+/- 0.083)\n",
      "\n",
      "n_clusters = 82 \n",
      "C = 2.000 \n",
      "Accuracy: 0.819 (+/- 0.074)\n",
      "\n",
      "n_clusters = 83 \n",
      "C = 0.500 \n",
      "Accuracy: 0.824 (+/- 0.072)\n",
      "\n",
      "n_clusters = 84 \n",
      "C = 0.500 \n",
      "Accuracy: 0.819 (+/- 0.071)\n",
      "\n",
      "n_clusters = 85 \n",
      "C = 0.500 \n",
      "Accuracy: 0.826 (+/- 0.072)\n",
      "\n",
      "n_clusters = 86 \n",
      "C = 0.500 \n",
      "Accuracy: 0.823 (+/- 0.068)\n",
      "\n",
      "n_clusters = 87 \n",
      "C = 32.000 \n",
      "Accuracy: 0.822 (+/- 0.079)\n",
      "\n",
      "n_clusters = 88 \n",
      "C = 0.500 \n",
      "Accuracy: 0.823 (+/- 0.073)\n",
      "\n",
      "n_clusters = 89 \n",
      "C = 0.250 \n",
      "Accuracy: 0.820 (+/- 0.099)\n",
      "\n",
      "n_clusters = 90 \n",
      "C = 0.500 \n",
      "Accuracy: 0.827 (+/- 0.075)\n",
      "\n",
      "n_clusters = 91 \n",
      "C = 0.250 \n",
      "Accuracy: 0.819 (+/- 0.093)\n",
      "\n",
      "n_clusters = 92 \n",
      "C = 0.500 \n",
      "Accuracy: 0.822 (+/- 0.060)\n",
      "\n",
      "n_clusters = 93 \n",
      "C = 0.500 \n",
      "Accuracy: 0.823 (+/- 0.068)\n",
      "\n",
      "n_clusters = 94 \n",
      "C = 0.500 \n",
      "Accuracy: 0.826 (+/- 0.069)\n",
      "\n",
      "n_clusters = 95 \n",
      "C = 0.500 \n",
      "Accuracy: 0.820 (+/- 0.067)\n",
      "\n",
      "n_clusters = 96 \n",
      "C = 0.500 \n",
      "Accuracy: 0.824 (+/- 0.072)\n",
      "\n",
      "n_clusters = 97 \n",
      "C = 0.500 \n",
      "Accuracy: 0.827 (+/- 0.070)\n",
      "\n",
      "n_clusters = 98 \n",
      "C = 0.500 \n",
      "Accuracy: 0.827 (+/- 0.070)\n",
      "\n",
      "n_clusters = 99 \n",
      "C = 0.500 \n",
      "Accuracy: 0.824 (+/- 0.076)\n",
      "\n",
      "n_clusters = 100 \n",
      "C = 0.500 \n",
      "Accuracy: 0.819 (+/- 0.076)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_clusters in range(2,101):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=44)\n",
    "    \n",
    "    X_train_cluster_dist = kmeans.fit_transform(X_train)\n",
    "    X_test_cluster_dist = kmeans.transform(X_test)\n",
    "    \n",
    "    scaler_cluster_dist = StandardScaler()\n",
    "    \n",
    "    X_train_cluster_dist = scaler_cluster_dist.fit_transform(X_train_cluster_dist)\n",
    "    X_test_cluster_dist = scaler_cluster_dist.transform(X_test_cluster_dist)\n",
    "    \n",
    "    X_train2 = np.hstack([X_train, X_train_cluster_dist])\n",
    "    X_test2 = np.hstack([X_test, X_test_cluster_dist])\n",
    "    \n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=44)\n",
    "    \n",
    "    best_mean = 0\n",
    "    best_std = 0\n",
    "    best_C = 0\n",
    "    for C in [2.0 ** i for i in range(-5, 10)]:\n",
    "        clf = LogisticRegression(C = C)\n",
    "        scores = cross_val_score(clf, X_train2, y_train, cv=kfold)\n",
    "        if (best_mean < scores.mean()):\n",
    "            best_mean = scores.mean()\n",
    "            best_std = scores.std()\n",
    "            best_C = C\n",
    "    print(\"n_clusters = %d \\nC = %0.3f \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (n_clusters, best_C, best_mean, best_std * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than baseline, but worse than SVM with RBF: ** 0.832 (+/- 0.061) **.\n",
    "\n",
    "Now test our model on different splitting to make sure, that we didn't overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.820 (+/- 0.098)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=32, random_state=44)\n",
    "\n",
    "X_train_cluster_dist = kmeans.fit_transform(X_train)\n",
    "X_test_cluster_dist = kmeans.transform(X_test)\n",
    "\n",
    "scaler_cluster_dist = StandardScaler()\n",
    "\n",
    "X_train_cluster_dist = scaler_cluster_dist.fit_transform(X_train_cluster_dist)\n",
    "X_test_cluster_dist = scaler_cluster_dist.transform(X_test_cluster_dist)\n",
    "\n",
    "X_train2 = np.hstack([X_train, X_train_cluster_dist])\n",
    "X_test2 = np.hstack([X_test, X_test_cluster_dist])\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42) # random_state = 42, before used 44\n",
    "\n",
    "clf = LogisticRegression(C = 8.0)\n",
    "\n",
    "scores = cross_val_score(clf, X_train2, y_train, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\\n\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is within the limits of error.\n",
    "\n",
    "Make a submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train2, y_train)\n",
    "y_pred = clf.predict(X_test2)\n",
    "ans = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived':y_pred})\n",
    "ans.to_csv(\"ans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is 0.80383. It is within the limits of error too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
