{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "Firstly, make imports, read data, pick out target column and find missings in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Name           1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "Age            1046 non-null float64\n",
      "SibSp          1309 non-null int64\n",
      "Parch          1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 122.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "y_train = np.array(train['Survived'])\n",
    "del train['Survived']\n",
    "\n",
    "X_all = pd.concat([train, test])\n",
    "print(X_all.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all machine learning algorithms work with numerical vectors. Convert data to appropriate format, filling in blanks and encode categorial features. Missing may be useful information, save it in additional column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all['age_null'] = pd.isnull(X_all['Age'])\n",
    "X_all['cabin_null'] = pd.isnull(X_all['Cabin'])\n",
    "\n",
    "X_all['isMale'] = X_all['Sex'] == 'male'\n",
    "\n",
    "X_all.fillna(value = {'Age': X_all['Age'].mean(),\n",
    "                      'Fare' : X_all['Fare'].mean(),\n",
    "                      'Embarked' : X_all['Embarked'].mode()[0]},\n",
    "             inplace = True)\n",
    "\n",
    "X_all['Embarked_S'] = X_all['Embarked'] == 'S'\n",
    "X_all['Embarked_C'] = X_all['Embarked'] == 'C'\n",
    "X_all['Embarked_Q'] = X_all['Embarked'] == 'Q'\n",
    "\n",
    "X_all['PClass_1'] = X_all['Pclass'] == 1\n",
    "X_all['PClass_2'] = X_all['Pclass'] == 2\n",
    "X_all['PClass_3'] = X_all['Pclass'] == 3\n",
    "\n",
    "del X_all['Cabin'], X_all['PassengerId'], X_all['Name'], X_all['Ticket'], X_all['Embarked'], X_all['Sex'], X_all['Pclass']\n",
    "\n",
    "X_train = np.array(X_all.iloc[train.index], dtype=np.dtype('float64'))\n",
    "X_test = np.array(X_all.iloc[X_train.shape[0]:], dtype=np.dtype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale all features with StandardScaler thus mean will be zero and standard deviation will be one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try linear model - logistic regression. Pick up regulazation parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.062 \n",
      "Accuracy: 0.804 (+/- 0.115)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=44)\n",
    "clf = LogisticRegression()\n",
    "param_grid = {'C' : [2.0 ** i for i in range(-5, 10)]}\n",
    "\n",
    "gridSearch = GridSearchCV(estimator=clf, param_grid=param_grid, cv=kfold)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"C = %0.3f \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (gridSearch.best_params_['C'],\n",
    "                                                     gridSearch.best_score_,\n",
    "                                                     gridSearch.cv_results_['std_test_score'][gridSearch.best_index_] * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our baseline is ** 0.804 (+/- 0.115) **\n",
    "\n",
    "Now try SVM with RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 2.000 \n",
      "Accuracy: 0.825 (+/- 0.083)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=44)\n",
    "clf = SVC()\n",
    "param_grid = {'C' : [2.0 ** i for i in range(-5, 10)], 'kernel': ['rbf']}\n",
    "\n",
    "gridSearch = GridSearchCV(estimator=clf, param_grid=param_grid, cv=kfold)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"C = %0.3f \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (gridSearch.best_params_['C'],\n",
    "                                                     gridSearch.best_score_,\n",
    "                                                     gridSearch.cv_results_['std_test_score'][gridSearch.best_index_] * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results improve to ** 0.825 (+/- 0.083) **\n",
    "\n",
    "Maybe it means that data have a cluster structure. \n",
    "Try K-nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 24 \n",
      "Accuracy: 0.808 (+/- 0.088)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=44)\n",
    "clf = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : range(1, 26)}\n",
    "\n",
    "gridSearch = GridSearchCV(estimator=clf, param_grid=param_grid, cv=kfold)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"n_neighbors = %d \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (gridSearch.best_params_['n_neighbors'],\n",
    "                                                            gridSearch.best_score_,\n",
    "                                                            gridSearch.cv_results_['std_test_score'][gridSearch.best_index_] * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are slightly better than logistic regression: ** 0.808 (+/- 0.088) **.\n",
    "Then try add information about cluster structure to features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 2 \n",
      "C = 0.062 \n",
      "Accuracy: 0.799 (+/- 0.113)\n",
      "\n",
      "n_clusters = 3 \n",
      "C = 0.062 \n",
      "Accuracy: 0.799 (+/- 0.113)\n",
      "\n",
      "n_clusters = 4 \n",
      "C = 0.031 \n",
      "Accuracy: 0.799 (+/- 0.109)\n",
      "\n",
      "n_clusters = 5 \n",
      "C = 1.000 \n",
      "Accuracy: 0.807 (+/- 0.083)\n",
      "\n",
      "n_clusters = 6 \n",
      "C = 1.000 \n",
      "Accuracy: 0.807 (+/- 0.080)\n",
      "\n",
      "n_clusters = 7 \n",
      "C = 0.500 \n",
      "Accuracy: 0.805 (+/- 0.074)\n",
      "\n",
      "n_clusters = 8 \n",
      "C = 2.000 \n",
      "Accuracy: 0.809 (+/- 0.090)\n",
      "\n",
      "n_clusters = 9 \n",
      "C = 2.000 \n",
      "Accuracy: 0.808 (+/- 0.091)\n",
      "\n",
      "n_clusters = 10 \n",
      "C = 2.000 \n",
      "Accuracy: 0.811 (+/- 0.086)\n",
      "\n",
      "n_clusters = 11 \n",
      "C = 2.000 \n",
      "Accuracy: 0.808 (+/- 0.103)\n",
      "\n",
      "n_clusters = 12 \n",
      "C = 0.500 \n",
      "Accuracy: 0.810 (+/- 0.074)\n",
      "\n",
      "n_clusters = 13 \n",
      "C = 4.000 \n",
      "Accuracy: 0.810 (+/- 0.105)\n",
      "\n",
      "n_clusters = 14 \n",
      "C = 2.000 \n",
      "Accuracy: 0.816 (+/- 0.083)\n",
      "\n",
      "n_clusters = 15 \n",
      "C = 64.000 \n",
      "Accuracy: 0.811 (+/- 0.067)\n",
      "\n",
      "n_clusters = 16 \n",
      "C = 2.000 \n",
      "Accuracy: 0.819 (+/- 0.071)\n",
      "\n",
      "n_clusters = 17 \n",
      "C = 4.000 \n",
      "Accuracy: 0.823 (+/- 0.091)\n",
      "\n",
      "n_clusters = 18 \n",
      "C = 2.000 \n",
      "Accuracy: 0.818 (+/- 0.066)\n",
      "\n",
      "n_clusters = 19 \n",
      "C = 2.000 \n",
      "Accuracy: 0.822 (+/- 0.080)\n",
      "\n",
      "n_clusters = 20 \n",
      "C = 32.000 \n",
      "Accuracy: 0.824 (+/- 0.075)\n",
      "\n",
      "n_clusters = 21 \n",
      "C = 2.000 \n",
      "Accuracy: 0.819 (+/- 0.084)\n",
      "\n",
      "n_clusters = 22 \n",
      "C = 0.500 \n",
      "Accuracy: 0.819 (+/- 0.079)\n",
      "\n",
      "n_clusters = 23 \n",
      "C = 8.000 \n",
      "Accuracy: 0.827 (+/- 0.074)\n",
      "\n",
      "n_clusters = 24 \n",
      "C = 4.000 \n",
      "Accuracy: 0.820 (+/- 0.077)\n",
      "\n",
      "n_clusters = 25 \n",
      "C = 0.500 \n",
      "Accuracy: 0.820 (+/- 0.086)\n",
      "\n",
      "n_clusters = 26 \n",
      "C = 0.500 \n",
      "Accuracy: 0.823 (+/- 0.082)\n",
      "\n",
      "n_clusters = 27 \n",
      "C = 4.000 \n",
      "Accuracy: 0.822 (+/- 0.071)\n",
      "\n",
      "n_clusters = 28 \n",
      "C = 2.000 \n",
      "Accuracy: 0.822 (+/- 0.068)\n",
      "\n",
      "n_clusters = 29 \n",
      "C = 4.000 \n",
      "Accuracy: 0.822 (+/- 0.076)\n",
      "\n",
      "n_clusters = 30 \n",
      "C = 4.000 \n",
      "Accuracy: 0.827 (+/- 0.070)\n",
      "\n",
      "n_clusters = 31 \n",
      "C = 8.000 \n",
      "Accuracy: 0.822 (+/- 0.066)\n",
      "\n",
      "n_clusters = 32 \n",
      "C = 4.000 \n",
      "Accuracy: 0.831 (+/- 0.078)\n",
      "\n",
      "n_clusters = 33 \n",
      "C = 64.000 \n",
      "Accuracy: 0.826 (+/- 0.080)\n",
      "\n",
      "n_clusters = 34 \n",
      "C = 8.000 \n",
      "Accuracy: 0.824 (+/- 0.071)\n",
      "\n",
      "n_clusters = 35 \n",
      "C = 8.000 \n",
      "Accuracy: 0.828 (+/- 0.061)\n",
      "\n",
      "n_clusters = 36 \n",
      "C = 8.000 \n",
      "Accuracy: 0.827 (+/- 0.067)\n",
      "\n",
      "n_clusters = 37 \n",
      "C = 4.000 \n",
      "Accuracy: 0.823 (+/- 0.076)\n",
      "\n",
      "n_clusters = 38 \n",
      "C = 4.000 \n",
      "Accuracy: 0.826 (+/- 0.067)\n",
      "\n",
      "n_clusters = 39 \n",
      "C = 4.000 \n",
      "Accuracy: 0.832 (+/- 0.060)\n",
      "\n",
      "n_clusters = 40 \n",
      "C = 8.000 \n",
      "Accuracy: 0.827 (+/- 0.070)\n",
      "\n",
      "n_clusters = 41 \n",
      "C = 8.000 \n",
      "Accuracy: 0.825 (+/- 0.066)\n",
      "\n",
      "n_clusters = 42 \n",
      "C = 2.000 \n",
      "Accuracy: 0.820 (+/- 0.072)\n",
      "\n",
      "n_clusters = 43 \n",
      "C = 16.000 \n",
      "Accuracy: 0.825 (+/- 0.066)\n",
      "\n",
      "n_clusters = 44 \n",
      "C = 4.000 \n",
      "Accuracy: 0.824 (+/- 0.063)\n",
      "\n",
      "n_clusters = 45 \n",
      "C = 4.000 \n",
      "Accuracy: 0.828 (+/- 0.068)\n",
      "\n",
      "n_clusters = 46 \n",
      "C = 8.000 \n",
      "Accuracy: 0.824 (+/- 0.062)\n",
      "\n",
      "n_clusters = 47 \n",
      "C = 4.000 \n",
      "Accuracy: 0.822 (+/- 0.073)\n",
      "\n",
      "n_clusters = 48 \n",
      "C = 256.000 \n",
      "Accuracy: 0.823 (+/- 0.071)\n",
      "\n",
      "n_clusters = 49 \n",
      "C = 0.250 \n",
      "Accuracy: 0.823 (+/- 0.088)\n",
      "\n",
      "n_clusters = 50 \n",
      "C = 1.000 \n",
      "Accuracy: 0.825 (+/- 0.068)\n",
      "\n",
      "n_clusters = 51 \n",
      "C = 4.000 \n",
      "Accuracy: 0.825 (+/- 0.076)\n",
      "\n",
      "n_clusters = 52 \n",
      "C = 4.000 \n",
      "Accuracy: 0.824 (+/- 0.070)\n",
      "\n",
      "n_clusters = 53 \n",
      "C = 16.000 \n",
      "Accuracy: 0.824 (+/- 0.067)\n",
      "\n",
      "n_clusters = 54 \n",
      "C = 8.000 \n",
      "Accuracy: 0.825 (+/- 0.062)\n",
      "\n",
      "n_clusters = 55 \n",
      "C = 0.250 \n",
      "Accuracy: 0.819 (+/- 0.092)\n",
      "\n",
      "n_clusters = 56 \n",
      "C = 4.000 \n",
      "Accuracy: 0.825 (+/- 0.066)\n",
      "\n",
      "n_clusters = 57 \n",
      "C = 2.000 \n",
      "Accuracy: 0.825 (+/- 0.065)\n",
      "\n",
      "n_clusters = 58 \n",
      "C = 4.000 \n",
      "Accuracy: 0.825 (+/- 0.071)\n",
      "\n",
      "n_clusters = 59 \n",
      "C = 2.000 \n",
      "Accuracy: 0.820 (+/- 0.078)\n",
      "\n",
      "n_clusters = 60 \n",
      "C = 1.000 \n",
      "Accuracy: 0.823 (+/- 0.070)\n",
      "\n",
      "n_clusters = 61 \n",
      "C = 0.250 \n",
      "Accuracy: 0.819 (+/- 0.085)\n",
      "\n",
      "n_clusters = 62 \n",
      "C = 2.000 \n",
      "Accuracy: 0.826 (+/- 0.071)\n",
      "\n",
      "n_clusters = 63 \n",
      "C = 1.000 \n",
      "Accuracy: 0.825 (+/- 0.076)\n",
      "\n",
      "n_clusters = 64 \n",
      "C = 0.250 \n",
      "Accuracy: 0.819 (+/- 0.089)\n",
      "\n",
      "n_clusters = 65 \n",
      "C = 0.250 \n",
      "Accuracy: 0.819 (+/- 0.085)\n",
      "\n",
      "n_clusters = 66 \n",
      "C = 4.000 \n",
      "Accuracy: 0.828 (+/- 0.061)\n",
      "\n",
      "n_clusters = 67 \n",
      "C = 1.000 \n",
      "Accuracy: 0.816 (+/- 0.079)\n",
      "\n",
      "n_clusters = 68 \n",
      "C = 1.000 \n",
      "Accuracy: 0.822 (+/- 0.081)\n",
      "\n",
      "n_clusters = 69 \n",
      "C = 0.250 \n",
      "Accuracy: 0.820 (+/- 0.092)\n",
      "\n",
      "n_clusters = 70 \n",
      "C = 1.000 \n",
      "Accuracy: 0.823 (+/- 0.088)\n",
      "\n",
      "n_clusters = 71 \n",
      "C = 0.250 \n",
      "Accuracy: 0.823 (+/- 0.098)\n",
      "\n",
      "n_clusters = 72 \n",
      "C = 2.000 \n",
      "Accuracy: 0.822 (+/- 0.066)\n",
      "\n",
      "n_clusters = 73 \n",
      "C = 0.250 \n",
      "Accuracy: 0.822 (+/- 0.094)\n",
      "\n",
      "n_clusters = 74 \n",
      "C = 0.250 \n",
      "Accuracy: 0.823 (+/- 0.096)\n",
      "\n",
      "n_clusters = 75 \n",
      "C = 2.000 \n",
      "Accuracy: 0.823 (+/- 0.069)\n",
      "\n",
      "n_clusters = 76 \n",
      "C = 2.000 \n",
      "Accuracy: 0.822 (+/- 0.082)\n",
      "\n",
      "n_clusters = 77 \n",
      "C = 0.500 \n",
      "Accuracy: 0.820 (+/- 0.090)\n",
      "\n",
      "n_clusters = 78 \n",
      "C = 1.000 \n",
      "Accuracy: 0.823 (+/- 0.074)\n",
      "\n",
      "n_clusters = 79 \n",
      "C = 0.250 \n",
      "Accuracy: 0.823 (+/- 0.097)\n",
      "\n",
      "n_clusters = 80 \n",
      "C = 1.000 \n",
      "Accuracy: 0.824 (+/- 0.067)\n",
      "\n",
      "n_clusters = 81 \n",
      "C = 0.250 \n",
      "Accuracy: 0.824 (+/- 0.090)\n",
      "\n",
      "n_clusters = 82 \n",
      "C = 2.000 \n",
      "Accuracy: 0.822 (+/- 0.071)\n",
      "\n",
      "n_clusters = 83 \n",
      "C = 1.000 \n",
      "Accuracy: 0.824 (+/- 0.074)\n",
      "\n",
      "n_clusters = 84 \n",
      "C = 0.500 \n",
      "Accuracy: 0.824 (+/- 0.084)\n",
      "\n",
      "n_clusters = 85 \n",
      "C = 0.250 \n",
      "Accuracy: 0.816 (+/- 0.090)\n",
      "\n",
      "n_clusters = 86 \n",
      "C = 0.125 \n",
      "Accuracy: 0.819 (+/- 0.084)\n",
      "\n",
      "n_clusters = 87 \n",
      "C = 0.500 \n",
      "Accuracy: 0.824 (+/- 0.084)\n",
      "\n",
      "n_clusters = 88 \n",
      "C = 0.500 \n",
      "Accuracy: 0.824 (+/- 0.079)\n",
      "\n",
      "n_clusters = 89 \n",
      "C = 1.000 \n",
      "Accuracy: 0.826 (+/- 0.078)\n",
      "\n",
      "n_clusters = 90 \n",
      "C = 0.500 \n",
      "Accuracy: 0.819 (+/- 0.082)\n",
      "\n",
      "n_clusters = 91 \n",
      "C = 1.000 \n",
      "Accuracy: 0.824 (+/- 0.073)\n",
      "\n",
      "n_clusters = 92 \n",
      "C = 0.500 \n",
      "Accuracy: 0.823 (+/- 0.087)\n",
      "\n",
      "n_clusters = 93 \n",
      "C = 0.250 \n",
      "Accuracy: 0.826 (+/- 0.091)\n",
      "\n",
      "n_clusters = 94 \n",
      "C = 0.250 \n",
      "Accuracy: 0.819 (+/- 0.094)\n",
      "\n",
      "n_clusters = 95 \n",
      "C = 1.000 \n",
      "Accuracy: 0.824 (+/- 0.075)\n",
      "\n",
      "n_clusters = 96 \n",
      "C = 0.125 \n",
      "Accuracy: 0.817 (+/- 0.088)\n",
      "\n",
      "n_clusters = 97 \n",
      "C = 0.250 \n",
      "Accuracy: 0.825 (+/- 0.088)\n",
      "\n",
      "n_clusters = 98 \n",
      "C = 0.125 \n",
      "Accuracy: 0.822 (+/- 0.091)\n",
      "\n",
      "n_clusters = 99 \n",
      "C = 0.250 \n",
      "Accuracy: 0.820 (+/- 0.092)\n",
      "\n",
      "n_clusters = 100 \n",
      "C = 0.250 \n",
      "Accuracy: 0.818 (+/- 0.089)\n",
      "\n",
      "\n",
      "\n",
      "best_n_clusters = 39\n"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "best_n_clusters = 0\n",
    "\n",
    "for n_clusters in range(2,101):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=44)\n",
    "    \n",
    "    X_train_cluster_dist = kmeans.fit_transform(X_train)\n",
    "    X_test_cluster_dist = kmeans.transform(X_test)\n",
    "    \n",
    "    scaler_cluster_dist = StandardScaler()\n",
    "    \n",
    "    X_train_cluster_dist = scaler_cluster_dist.fit_transform(X_train_cluster_dist)\n",
    "    X_test_cluster_dist = scaler_cluster_dist.transform(X_test_cluster_dist)\n",
    "    \n",
    "    X_train2 = np.hstack([X_train, X_train_cluster_dist])\n",
    "    X_test2 = np.hstack([X_test, X_test_cluster_dist])\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=44)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    param_grid = {'C' : [2.0 ** i for i in range(-5, 10)]}\n",
    "    \n",
    "    gridSearch = GridSearchCV(estimator=clf, param_grid=param_grid, cv=kfold)\n",
    "    gridSearch.fit(X_train2, y_train)\n",
    "    \n",
    "    print(\"n_clusters = %d \\nC = %0.3f \\nAccuracy: %0.3f (+/- %0.3f)\\n\" % (n_clusters,\n",
    "                                                                           gridSearch.best_params_['C'],\n",
    "                                                                           gridSearch.best_score_,\n",
    "                                                                           gridSearch.cv_results_['std_test_score'][gridSearch.best_index_] * 2))\n",
    "    if best_score < gridSearch.best_score_:\n",
    "        best_score = gridSearch.best_score_\n",
    "        best_n_clusters = n_clusters\n",
    "\n",
    "print(\"\\n\\nbest_n_clusters = %d\" % best_n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than baseline: ** 0.832 (+/- 0.060) ** (n_clusters = 39, C = 4.000).\n",
    "\n",
    "Now test our model on different splitting to make sure, that we didn't overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.820 (+/- 0.097)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=39, random_state=44)\n",
    "\n",
    "X_train_cluster_dist = kmeans.fit_transform(X_train)\n",
    "X_test_cluster_dist = kmeans.transform(X_test)\n",
    "\n",
    "scaler_cluster_dist = StandardScaler()\n",
    "\n",
    "X_train_cluster_dist = scaler_cluster_dist.fit_transform(X_train_cluster_dist)\n",
    "X_test_cluster_dist = scaler_cluster_dist.transform(X_test_cluster_dist)\n",
    "\n",
    "X_train2 = np.hstack([X_train, X_train_cluster_dist])\n",
    "X_test2 = np.hstack([X_test, X_test_cluster_dist])\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42) # random_state = 42, before used 44\n",
    "\n",
    "clf = LogisticRegression(C = 4.0)\n",
    "\n",
    "scores = cross_val_score(clf, X_train2, y_train, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\\n\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is within the limits of error.\n",
    "\n",
    "Make a submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train2, y_train)\n",
    "y_pred = clf.predict(X_test2)\n",
    "ans = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived':y_pred})\n",
    "ans.to_csv(\"ans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is 0.77990. It is within the limits of error too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
